# Chapitre 4 : Data & Gouvernance

*Temps de lecture estimÃ© : 45 minutes*

## Introduction : La DonnÃ©e comme Actif StratÃ©gique

L'intelligence artificielle n'est que le reflet de la qualitÃ© de ses donnÃ©es. Sans gouvernance robuste, mÃªme les modÃ¨les les plus sophistiquÃ©s produiront des rÃ©sultats mÃ©diocres, biaisÃ©s ou non conformes. Ce chapitre vous donne les clÃ©s pour construire une architecture de donnÃ©es fiable, sÃ©curisÃ©e et conforme aux rÃ©glementations europÃ©ennes.

Dans ce chapitre, nous couvrons :
- **Architecture de donnÃ©es** pour l'IA moderne
- **ConformitÃ© RGPD** et protection des donnÃ©es personnelles
- **QualitÃ© des donnÃ©es** et processus de validation
- **Privacy-preserving AI** et techniques avancÃ©es
- **Audit et traÃ§abilitÃ©** des modÃ¨les IA

## ğŸ—ï¸ Architecture de DonnÃ©es pour l'IA

### Le Data Stack Moderne

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA SOURCES  â”‚    â”‚  DATA PLATFORM  â”‚    â”‚  AI/ML LAYER    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Transactional â”‚â”€â”€â”€â”€â”‚ â€¢ Data Lake     â”‚â”€â”€â”€â”€â”‚ â€¢ Feature Store â”‚
â”‚ â€¢ Streaming     â”‚    â”‚ â€¢ Data Warehouseâ”‚    â”‚ â€¢ Model Registryâ”‚
â”‚ â€¢ External APIs â”‚    â”‚ â€¢ Data Catalog  â”‚    â”‚ â€¢ ML Pipelines  â”‚
â”‚ â€¢ Documents     â”‚    â”‚ â€¢ Governance    â”‚    â”‚ â€¢ Inference API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   GOVERNANCE    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ â€¢ Data Quality  â”‚
                    â”‚ â€¢ Privacy       â”‚
                    â”‚ â€¢ Lineage       â”‚
                    â”‚ â€¢ Access Controlâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### StratÃ©gie Data Lake vs Data Warehouse

**Comparaison architecturale :**

| Aspect | Data Lake | Data Warehouse | Lakehouse (Hybride) |
|--------|-----------|----------------|-------------------|
| **Structure** | Schema-on-read | Schema-on-write | Schema evolution |
| **Formats** | Tous formats | StructurÃ© uniquement | Multi-format |
| **CoÃ»t stockage** | TrÃ¨s bas | Ã‰levÃ© | ModÃ©rÃ© |
| **Time-to-insight** | Variable | Rapide | Rapide |
| **Governance** | Complexe | Native | IntÃ©grÃ©e |
| **ML/AI** | Excellent | LimitÃ© | Optimal |

**Recommandation architecture moderne :**
```yaml
# Modern Data Architecture for AI
data_platform:
  storage_layer:
    raw_data: 
      technology: "AWS S3 / Azure Data Lake"
      formats: ["parquet", "delta", "json", "csv"]
      retention: "7 years"
      
    processed_data:
      technology: "Delta Lake / Apache Iceberg"  
      features: ["ACID transactions", "time travel", "schema evolution"]
      
    vector_storage:
      technology: "Pinecone / Weaviate / ChromaDB"
      use_case: "Embeddings for RAG applications"
      
  processing_layer:
    batch_processing:
      technology: "Apache Spark / Databricks"
      schedule: "Daily ETL + Weekly ML retraining"
      
    stream_processing:
      technology: "Apache Kafka / Kinesis"
      use_case: "Real-time feature computation"
      
  governance_layer:
    data_catalog: "Apache Atlas / AWS Glue Data Catalog"
    lineage_tracking: "DataHub / Apache Atlas"
    quality_monitoring: "Great Expectations / Deequ"
    access_control: "Apache Ranger / Unity Catalog"
```

### Bases de DonnÃ©es Vectorielles

**Choix de solution selon le cas d'usage :**

```python
# Guide de sÃ©lection base vectorielle
def select_vector_db(requirements):
    """
    SÃ©lectionne la base vectorielle optimale selon les critÃ¨res
    """
    solutions = {
        "pinecone": {
            "best_for": "Production scale, managed service",
            "pros": ["Performance", "ScalabilitÃ©", "Managed"],
            "cons": ["CoÃ»t", "Vendor lock-in"],
            "max_vectors": "Unlimited",
            "latency": "<50ms",
            "cost": "High"
        },
        "weaviate": {
            "best_for": "Multi-modal AI, semantic search",
            "pros": ["Open source", "Multi-modal", "GraphQL"],
            "cons": ["ComplexitÃ© setup", "Moins mature"],
            "max_vectors": "Billions", 
            "latency": "<100ms",
            "cost": "Medium"
        },
        "chromadb": {
            "best_for": "Prototyping, small scale",
            "pros": ["Simple", "Gratuit", "Local"],
            "cons": ["Performance limitÃ©e", "Pas pour prod"],
            "max_vectors": "Millions",
            "latency": "Variable",
            "cost": "Free"
        },
        "elasticsearch": {
            "best_for": "Search existant, budget contraint",
            "pros": ["Ã‰cosystÃ¨me mature", "Multi-usage"],
            "cons": ["Pas optimisÃ© IA", "ComplexitÃ©"],
            "max_vectors": "Billions",
            "latency": "100-200ms", 
            "cost": "Low-Medium"
        }
    }
    
    # Logique de sÃ©lection
    if requirements["scale"] == "enterprise" and requirements["budget"] == "high":
        return solutions["pinecone"]
    elif requirements["multi_modal"] == True:
        return solutions["weaviate"]
    elif requirements["stage"] == "prototype":
        return solutions["chromadb"]
    else:
        return solutions["elasticsearch"]

# Exemple d'usage
requirements = {
    "scale": "enterprise",
    "budget": "high", 
    "latency_requirement": 50,  # ms
    "vector_count": 100_000_000,
    "multi_modal": False
}

recommended_db = select_vector_db(requirements)
```

**Architecture RAG optimisÃ©e :**
```yaml
# Production RAG Architecture
rag_system:
  data_ingestion:
    documents: 
      - "PDF extraction with OCR fallback"
      - "Structured data (JSON, CSV, DB)"
      - "Real-time API feeds"
      
    preprocessing:
      - "Document chunking (semantic-aware)"
      - "Metadata extraction"
      - "Quality filtering"
      
  vector_pipeline:
    embedding_model: "text-embedding-ada-002"
    chunk_size: 1000
    chunk_overlap: 200
    
    indexing_strategy:
      hierarchical: "Document â†’ Section â†’ Paragraph"
      metadata_filters: ["department", "date", "category"]
      
  retrieval_system:
    primary_search: "Vector similarity (top-k=20)"
    reranking: "Cross-encoder model (top-3)"
    hybrid_search: "Vector + keyword (BM25)"
    
  governance:
    access_control: "Document-level permissions"
    audit_logging: "All queries logged with user context"
    privacy_filtering: "PII detection and masking"
```

## ğŸ“‹ ConformitÃ© RGPD et Protection des DonnÃ©es

### Framework de ConformitÃ© RGPD

**Les 7 Principes Fondamentaux :**

1. **LicÃ©itÃ©, loyautÃ© et transparence**
2. **Limitation des finalitÃ©s** 
3. **Minimisation des donnÃ©es**
4. **Exactitude**
5. **Limitation de la conservation**
6. **IntÃ©gritÃ© et confidentialitÃ©**
7. **ResponsabilitÃ©**

### Analyse d'Impact RGPD (AIPD) pour l'IA

**Template AIPD spÃ©cialisÃ© IA :**

```markdown
# ANALYSE D'IMPACT PROTECTION DES DONNÃ‰ES - Projet IA

## 1. DESCRIPTION DU PROJET
**Nom du projet :** [SystÃ¨me IA de recommandation produits]
**FinalitÃ© :** [Personnaliser l'expÃ©rience client et augmenter les ventes]
**Base lÃ©gale :** [IntÃ©rÃªt lÃ©gitime / Consentement / ExÃ©cution contrat]

## 2. DONNÃ‰ES TRAITÃ‰ES

### CatÃ©gories de donnÃ©es personnelles :
- [ ] DonnÃ©es d'identification (nom, email, ID client)
- [ ] DonnÃ©es comportementales (clics, achats, navigation)
- [ ] DonnÃ©es techniques (IP, cookies, device fingerprint)
- [ ] DonnÃ©es dÃ©rivÃ©es (scores, segments, prÃ©dictions)

### DonnÃ©es sensibles (Art. 9 RGPD) :
- [ ] Origine raciale/ethnique
- [ ] Opinions politiques
- [ ] Convictions religieuses
- [ ] DonnÃ©es de santÃ©
- [ ] DonnÃ©es biomÃ©triques

## 3. ACTEURS ET FLUX
```mermaid
graph TD
    A[Client] -->|DonnÃ©es comportement| B[SystÃ¨me IA]
    B -->|Recommandations| A
    B -->|ModÃ¨les| C[Data Scientists]
    B -->|MÃ©triques| D[Marketing]
    E[Prestataire Cloud] -->|HÃ©bergement| B
    F[Partenaire Data] -->|Enrichissement| B
```

## 4. RISQUES IDENTIFIÃ‰S

| Risque | Impact | ProbabilitÃ© | Niveau | Mesures d'attÃ©nuation |
|--------|--------|-------------|--------|----------------------|
| **Biais algorithmique** | Ã‰levÃ© | Moyenne | ğŸ”´ Ã‰levÃ© | Audit rÃ©gulier, datasets diversifiÃ©s |
| **Re-identification** | TrÃ¨s Ã©levÃ© | Faible | ğŸŸ  Moyen | Anonymisation k-anonymity |
| **Profilage abusif** | Moyen | Ã‰levÃ©e | ğŸŸ  Moyen | Limitation finalitÃ©s, droit opposition |
| **Fuite de donnÃ©es** | TrÃ¨s Ã©levÃ© | Faible | ğŸŸ  Moyen | Chiffrement, access control |

## 5. MESURES DE PROTECTION

### Privacy by Design :
- [ ] Minimisation donnÃ©es (collecte strict nÃ©cessaire)
- [ ] Pseudonymisation des identifiants
- [ ] Chiffrement end-to-end
- [ ] Audit trails complets
- [ ] Tests d'adversarial attacks

### Droits des personnes concernÃ©es :
- [ ] Information transparente (notice IA)
- [ ] Droit d'accÃ¨s (export donnÃ©es + explications)  
- [ ] Droit de rectification
- [ ] Droit d'opposition au profilage
- [ ] Droit Ã  l'explication des dÃ©cisions automatisÃ©es
```

### ImplÃ©mentation Technique RGPD

**Pseudonymisation avancÃ©e :**
```python
import hashlib
import hmac
from cryptography.fernet import Fernet

class GDPRCompliantPseudonymizer:
    def __init__(self, master_key: str):
        self.master_key = master_key.encode()
        self.fernet = Fernet(Fernet.generate_key())
        
    def pseudonymize_user_id(self, user_id: str, purpose: str) -> str:
        """
        Pseudonymisation contextuelle selon la finalitÃ©
        Permet la re-identification si nÃ©cessaire tout en protÃ©geant
        """
        # Salt unique par finalitÃ©
        purpose_salt = hmac.new(
            self.master_key, 
            purpose.encode(), 
            hashlib.sha256
        ).digest()
        
        # Hash avec salt contextuel  
        pseudo_id = hmac.new(
            purpose_salt,
            user_id.encode(),
            hashlib.sha256
        ).hexdigest()
        
        return f"pseudo_{purpose}_{pseudo_id[:16]}"
    
    def anonymize_for_ml(self, dataframe, quasi_identifiers):
        """
        K-anonymitÃ© pour jeux de donnÃ©es ML
        """
        # ImplÃ©mentation k-anonymity avec suppression/gÃ©nÃ©ralisation
        k = 5  # Minimum 5 individus par groupe
        
        for column in quasi_identifiers:
            # GÃ©nÃ©ralisation hiÃ©rarchique
            if dataframe[column].dtype == 'datetime64[ns]':
                # Date â†’ AnnÃ©e-Mois
                dataframe[column] = dataframe[column].dt.to_period('M')
            elif dataframe[column].dtype == 'int64':
                # Age â†’ Tranches d'Ã¢ge  
                dataframe[column] = pd.cut(dataframe[column], bins=5)
                
        # VÃ©rification k-anonymity
        group_sizes = dataframe.groupby(quasi_identifiers).size()
        if (group_sizes < k).any():
            # Suppression records problÃ©matiques
            valid_groups = group_sizes[group_sizes >= k].index
            dataframe = dataframe.set_index(quasi_identifiers).loc[valid_groups].reset_index()
            
        return dataframe

# Usage
pseudonymizer = GDPRCompliantPseudonymizer("your-master-key")
training_user_id = pseudonymizer.pseudonymize_user_id("user123", "ml_training")
analytics_user_id = pseudonymizer.pseudonymize_user_id("user123", "analytics")
```

**Gestion du Consentement :**
```javascript
// Consent Management for AI Systems
class AIConsentManager {
    constructor() {
        this.purposes = {
            'personalization': {
                name: 'Personalisation des recommandations',
                description: 'Utilise vos donnÃ©es d\'achat pour des suggestions personnalisÃ©es',
                legal_basis: 'consent',
                data_categories: ['purchase_history', 'browsing_behavior'],
                retention_period: '24 months',
                automated_decision: true
            },
            'fraud_detection': {
                name: 'DÃ©tection de fraude',
                description: 'Analyse automatique pour protÃ©ger votre compte',
                legal_basis: 'legitimate_interest',
                data_categories: ['transaction_data', 'device_info'],
                retention_period: '36 months',
                automated_decision: true
            }
        };
    }
    
    async getConsentStatus(userId, purpose) {
        const consent = await this.db.getConsent(userId, purpose);
        return {
            granted: consent.status === 'granted',
            timestamp: consent.timestamp,
            expiry: this.calculateExpiry(consent.timestamp),
            withdrawal_method: '/privacy/withdraw-consent'
        };
    }
    
    async recordConsentChange(userId, purpose, granted, source = 'user_action') {
        const record = {
            user_id: userId,
            purpose: purpose,
            status: granted ? 'granted' : 'withdrawn',
            timestamp: new Date(),
            source: source,
            ip_address: this.hashIP(request.ip),
            user_agent_hash: this.hashUserAgent(request.userAgent)
        };
        
        await this.db.recordConsent(record);
        
        // Propagation aux systÃ¨mes ML
        if (!granted) {
            await this.mlSystem.removeUserData(userId, purpose);
            await this.vectorDB.deleteUserVectors(userId, purpose);
        }
    }
}
```

## ğŸ” QualitÃ© des DonnÃ©es et Validation

### Framework de Data Quality

**Les 6 Dimensions de la QualitÃ© :**

1. **ComplÃ©tude** - Absence de valeurs manquantes critiques
2. **Exactitude** - ConformitÃ© avec la rÃ©alitÃ©  
3. **CohÃ©rence** - UniformitÃ© Ã  travers les systÃ¨mes
4. **ValiditÃ©** - Respect des formats et contraintes
5. **ActualitÃ©** - FraÃ®cheur et mise Ã  jour
6. **UnicitÃ©** - Absence de doublons

### ImplÃ©mentation Great Expectations

```python
import great_expectations as ge
from great_expectations.dataset import Dataset

class AIDataValidator:
    def __init__(self, data_context_path: str):
        self.context = ge.get_context(context_root_dir=data_context_path)
        
    def create_ml_dataset_expectations(self, dataset_name: str):
        """
        CrÃ©e les attentes de qualitÃ© pour un dataset ML
        """
        suite_name = f"{dataset_name}_ml_suite"
        suite = self.context.create_expectation_suite(suite_name)
        
        # Expectations communes pour ML
        expectations = [
            # ComplÃ©tude
            {
                "expectation_type": "expect_column_values_to_not_be_null",
                "kwargs": {"column": "target_variable"}
            },
            
            # Distribution des classes (pas de class imbalance extrÃªme)
            {
                "expectation_type": "expect_column_proportion_of_unique_values_to_be_between", 
                "kwargs": {
                    "column": "target_variable",
                    "min_value": 0.01,  # Au moins 1% par classe
                    "max_value": 0.99   # Pas plus de 99% d'une classe
                }
            },
            
            # Pas de dÃ©rive statistique
            {
                "expectation_type": "expect_column_mean_to_be_between",
                "kwargs": {
                    "column": "feature_numeric", 
                    "min_value": -3,  # 3 Ã©carts-types de la baseline
                    "max_value": 3
                }
            },
            
            # DÃ©tection d'outliers
            {
                "expectation_type": "expect_column_quantile_values_to_be_between",
                "kwargs": {
                    "column": "feature_numeric",
                    "quantile_ranges": {
                        "quantiles": [0.01, 0.99],
                        "value_ranges": [[-100, 100], [-100, 100]]
                    }
                }
            }
        ]
        
        for expectation in expectations:
            suite.add_expectation(**expectation)
            
        return suite
        
    def validate_training_data(self, df, suite_name: str):
        """
        Valide un dataset d'entraÃ®nement avant utilisation
        """
        batch = ge.dataset.PandasDataset(df)
        
        results = batch.validate(
            expectation_suite_name=suite_name,
            result_format="SUMMARY"
        )
        
        if not results["success"]:
            failed_expectations = [
                exp for exp in results["results"] 
                if not exp["success"]
            ]
            
            raise DataQualityError(
                f"Data validation failed: {len(failed_expectations)} issues",
                details=failed_expectations
            )
            
        return results

# Configuration monitoring continu
data_quality_config = {
    "monitoring_schedule": "daily",
    "alert_thresholds": {
        "completeness": 0.95,      # 95% complÃ©tude minimum
        "accuracy": 0.90,          # 90% exactitude minimum  
        "freshness_hours": 24,     # DonnÃ©es < 24h
        "schema_changes": 0        # Aucun changement schema non approuvÃ©
    },
    "notifications": {
        "slack_channel": "#data-quality-alerts",
        "email_list": ["data-team@company.com"],
        "severity_levels": ["WARNING", "ERROR", "CRITICAL"]
    }
}
```

### Data Lineage et TraÃ§abilitÃ©

**ImplÃ©mentation avec Apache Atlas :**
```python
from pyatlas import Atlas
import json

class AIDataLineageTracker:
    def __init__(self, atlas_endpoint: str):
        self.atlas = Atlas(atlas_endpoint)
        
    def track_ml_pipeline(self, pipeline_run):
        """
        Enregistre la lignÃ©e complÃ¨te d'un pipeline ML
        """
        entities = []
        
        # Dataset source
        source_entity = {
            "typeName": "DataSet",
            "attributes": {
                "name": pipeline_run["source_dataset"],
                "qualifiedName": f"{pipeline_run['source_dataset']}@{pipeline_run['environment']}",
                "description": "Source dataset for ML training",
                "uri": pipeline_run["source_uri"]
            }
        }
        entities.append(source_entity)
        
        # Feature engineering process  
        fe_process = {
            "typeName": "Process",
            "attributes": {
                "name": f"feature_engineering_{pipeline_run['pipeline_id']}",
                "qualifiedName": f"fe_process_{pipeline_run['pipeline_id']}@{pipeline_run['environment']}",
                "inputs": [source_entity["attributes"]["qualifiedName"]],
                "outputs": [f"features_{pipeline_run['pipeline_id']}@{pipeline_run['environment']}"]
            }
        }
        entities.append(fe_process)
        
        # ModÃ¨le ML
        model_entity = {
            "typeName": "MLModel", 
            "attributes": {
                "name": f"model_{pipeline_run['model_name']}",
                "qualifiedName": f"model_{pipeline_run['model_name']}_v{pipeline_run['version']}@{pipeline_run['environment']}",
                "algorithm": pipeline_run["algorithm"],
                "hyperparameters": json.dumps(pipeline_run["hyperparameters"]),
                "performance_metrics": json.dumps(pipeline_run["metrics"]),
                "training_dataset": f"features_{pipeline_run['pipeline_id']}@{pipeline_run['environment']}"
            }
        }
        entities.append(model_entity)
        
        # Enregistrement dans Atlas
        response = self.atlas.entity.create_entities(entities)
        return response
        
    def query_model_lineage(self, model_name: str):
        """
        RÃ©cupÃ¨re la lignÃ©e complÃ¨te d'un modÃ¨le
        """
        lineage = self.atlas.lineage.get_lineage(
            guid=self.get_model_guid(model_name),
            direction="BOTH",
            depth=10
        )
        
        return {
            "upstream_datasets": self.extract_upstream_datasets(lineage),
            "downstream_applications": self.extract_downstream_apps(lineage),
            "transformation_steps": self.extract_transformations(lineage)
        }
```

## ğŸ” Privacy-Preserving AI

### Techniques d'Anonymisation AvancÃ©es

**Differential Privacy pour ML :**
```python
import numpy as np
from diffprivlib.models import GaussianNB
from diffprivlib.mechanisms import Laplace

class DifferentiallyPrivateML:
    def __init__(self, epsilon: float = 1.0):
        """
        epsilon: paramÃ¨tre de confidentialitÃ©
        Plus petit = plus privÃ© mais moins prÃ©cis
        """
        self.epsilon = epsilon
        self.laplace = Laplace(epsilon=epsilon, delta=0.0)
        
    def train_private_model(self, X, y):
        """
        EntraÃ®ne un modÃ¨le avec differential privacy
        """
        # ModÃ¨le avec DP intÃ©grÃ©
        model = GaussianNB(
            epsilon=self.epsilon,
            bounds=self._compute_bounds(X)
        )
        
        model.fit(X, y)
        return model
        
    def add_noise_to_gradients(self, gradients, sensitivity):
        """
        Ajoute du bruit aux gradients pour DP-SGD
        """
        noisy_gradients = []
        for gradient in gradients:
            # Clipping pour borner la sensibilitÃ©
            clipped_gradient = np.clip(gradient, -sensitivity, sensitivity)
            
            # Ajout de bruit Gaussien
            noise = np.random.normal(0, sensitivity * np.sqrt(2 * np.log(1.25)) / self.epsilon, clipped_gradient.shape)
            noisy_gradient = clipped_gradient + noise
            
            noisy_gradients.append(noisy_gradient)
        
        return noisy_gradients
    
    def private_data_release(self, data, query_func):
        """
        Publication de statistiques avec garanties DP
        """
        true_result = query_func(data)
        noisy_result = self.laplace.randomise(true_result)
        
        return noisy_result

# Federated Learning Setup
class FederatedLearningCoordinator:
    def __init__(self, num_clients: int, privacy_budget: float):
        self.clients = num_clients
        self.epsilon = privacy_budget
        
    def coordinate_training(self, global_model, client_data_loaders):
        """
        Coordination d'entraÃ®nement fÃ©dÃ©rÃ© avec privacy
        """
        for round in range(self.num_rounds):
            client_updates = []
            
            for client_id, data_loader in enumerate(client_data_loaders):
                # EntraÃ®nement local avec DP
                local_model = self.train_local_model(
                    global_model, 
                    data_loader,
                    epsilon=self.epsilon/self.num_rounds  # Composition DP
                )
                
                # Seulement les gradients sont partagÃ©s
                client_updates.append(local_model.get_gradients())
            
            # AgrÃ©gation sÃ©curisÃ©e
            global_model = self.aggregate_updates(global_model, client_updates)
            
        return global_model
```

### Homomorphic Encryption pour IA

```python
from phe import paillier
import numpy as np

class HomomorphicMLInference:
    def __init__(self):
        self.public_key, self.private_key = paillier.generate_paillier_keypair()
        
    def encrypt_dataset(self, X):
        """
        Chiffre un dataset pour infÃ©rence sÃ©curisÃ©e
        """
        encrypted_X = []
        for row in X:
            encrypted_row = [self.public_key.encrypt(float(x)) for x in row]
            encrypted_X.append(encrypted_row)
        return encrypted_X
    
    def secure_linear_prediction(self, encrypted_features, model_weights):
        """
        PrÃ©diction linÃ©aire sur donnÃ©es chiffrÃ©es
        """
        encrypted_predictions = []
        
        for encrypted_row in encrypted_features:
            # Calcul du produit scalaire chiffrÃ©
            encrypted_sum = self.public_key.encrypt(0)
            
            for i, (encrypted_feature, weight) in enumerate(zip(encrypted_row, model_weights)):
                # Multiplication homomorphe (feature chiffrÃ©e Ã— weight en clair)
                encrypted_product = encrypted_feature * weight
                encrypted_sum += encrypted_product
                
            encrypted_predictions.append(encrypted_sum)
            
        return encrypted_predictions
    
    def decrypt_results(self, encrypted_predictions):
        """
        DÃ©chiffre les rÃ©sultats cÃ´tÃ© possesseur de la clÃ© privÃ©e
        """
        return [self.private_key.decrypt(pred) for pred in encrypted_predictions]

# Usage pour infÃ©rence confidentielle
he_system = HomomorphicMLInference()

# CÃ´tÃ© client : chiffrement des donnÃ©es
client_data = np.array([[1.2, 3.4, 5.6], [2.1, 4.3, 6.5]])
encrypted_data = he_system.encrypt_dataset(client_data)

# CÃ´tÃ© serveur : infÃ©rence sur donnÃ©es chiffrÃ©es
model_weights = [0.5, -0.3, 0.8]
encrypted_results = he_system.secure_linear_prediction(encrypted_data, model_weights)

# CÃ´tÃ© client : dÃ©chiffrement des rÃ©sultats
predictions = he_system.decrypt_results(encrypted_results)
```

## ğŸ“Š Audit et TraÃ§abilitÃ© des ModÃ¨les

### Model Registry et Versioning

```python
import mlflow
import hashlib
import json
from datetime import datetime

class AIModelGovernance:
    def __init__(self, mlflow_tracking_uri: str):
        mlflow.set_tracking_uri(mlflow_tracking_uri)
        self.client = mlflow.tracking.MlflowClient()
        
    def register_model_with_governance(self, model, model_name: str, 
                                     training_data_signature: str,
                                     governance_metadata: dict):
        """
        Enregistre un modÃ¨le avec mÃ©tadonnÃ©es de gouvernance complÃ¨tes
        """
        with mlflow.start_run() as run:
            # Enregistrement modÃ¨le standard
            mlflow.sklearn.log_model(model, "model")
            
            # MÃ©tadonnÃ©es de gouvernance
            governance_tags = {
                "data_source": governance_metadata["data_source"],
                "training_date": datetime.now().isoformat(),
                "data_signature": training_data_signature,
                "gdpr_compliant": governance_metadata.get("gdpr_compliant", False),
                "bias_tested": governance_metadata.get("bias_tested", False),
                "performance_baseline": json.dumps(governance_metadata["metrics"]),
                "approved_for_production": False,  # Require explicit approval
                "data_retention_policy": governance_metadata.get("retention_policy", "2_years")
            }
            
            mlflow.set_tags(governance_tags)
            
            # Hash du code d'entraÃ®nement pour reproductibilitÃ©
            training_code_hash = self.hash_training_code(governance_metadata["training_script"])
            mlflow.log_param("training_code_hash", training_code_hash)
            
            # Enregistrement dans le registry
            model_version = mlflow.register_model(
                model_uri=f"runs:/{run.info.run_id}/model",
                name=model_name
            )
            
            return model_version
    
    def approve_model_for_production(self, model_name: str, version: int, 
                                   approver: str, approval_criteria: dict):
        """
        Processus d'approbation formelle pour dÃ©ploiement
        """
        # VÃ©rification critÃ¨res d'approbation
        model_version = self.client.get_model_version(model_name, version)
        
        checks_passed = self.validate_approval_criteria(model_version, approval_criteria)
        
        if checks_passed:
            # Transition vers Production
            self.client.transition_model_version_stage(
                name=model_name,
                version=version,
                stage="Production"
            )
            
            # Log d'audit
            self.client.set_model_version_tag(
                name=model_name,
                version=version,
                key="production_approval",
                value=json.dumps({
                    "approver": approver,
                    "approval_date": datetime.now().isoformat(),
                    "criteria_met": approval_criteria,
                    "approval_id": self.generate_approval_id()
                })
            )
        else:
            raise ModelApprovalError("Model doesn't meet production criteria")
    
    def generate_model_audit_report(self, model_name: str, version: int):
        """
        GÃ©nÃ¨re un rapport d'audit complet pour un modÃ¨le
        """
        model_version = self.client.get_model_version(model_name, version)
        run = self.client.get_run(model_version.run_id)
        
        audit_report = {
            "model_info": {
                "name": model_name,
                "version": version,
                "status": model_version.current_stage,
                "creation_date": model_version.creation_timestamp
            },
            
            "data_governance": {
                "data_source": run.data.tags.get("data_source"),
                "data_signature": run.data.tags.get("data_signature"),  
                "gdpr_compliance": run.data.tags.get("gdpr_compliant") == "True",
                "retention_policy": run.data.tags.get("data_retention_policy")
            },
            
            "performance": {
                "metrics": json.loads(run.data.tags.get("performance_baseline", "{}")),
                "bias_analysis": self.get_bias_analysis(model_version),
                "drift_monitoring": self.get_drift_status(model_name, version)
            },
            
            "approval_history": self.get_approval_history(model_name, version),
            "usage_statistics": self.get_usage_stats(model_name, version),
            "security_scan": self.get_security_scan_results(model_name, version)
        }
        
        return audit_report

# Automatisation compliance checking
class ComplianceChecker:
    def __init__(self):
        self.rules = {
            "gdpr": {
                "required_tags": ["data_source", "gdpr_compliant", "retention_policy"],
                "data_minimization": True,
                "consent_tracking": True
            },
            "bias_detection": {
                "fairness_metrics": ["demographic_parity", "equalized_odds"],
                "protected_attributes": ["age", "gender", "ethnicity"],
                "threshold": 0.1  # Maximum bias allowed
            },
            "security": {
                "adversarial_robustness": True,
                "input_validation": True,
                "model_encryption": "at_rest"
            }
        }
    
    def check_model_compliance(self, model_metadata: dict):
        """
        VÃ©rifie la conformitÃ© d'un modÃ¨le selon les rÃ¨gles dÃ©finies
        """
        compliance_results = {}
        
        for regulation, requirements in self.rules.items():
            compliance_results[regulation] = self.check_regulation_compliance(
                model_metadata, requirements
            )
        
        overall_compliant = all(result["compliant"] for result in compliance_results.values())
        
        return {
            "overall_compliant": overall_compliant,
            "regulation_details": compliance_results,
            "recommendations": self.generate_compliance_recommendations(compliance_results)
        }
```

## âœ… Checklist de Gouvernance des DonnÃ©es

### Phase Setup (Semaine 1-2)
- [ ] **Architecture de donnÃ©es** dÃ©finie (Lake/Warehouse/Lakehouse)
- [ ] **Catalogage automatique** des sources de donnÃ©es configurÃ©
- [ ] **Politiques de rÃ©tention** dÃ©finies par type de donnÃ©es
- [ ] **Access control** basÃ© sur les rÃ´les implÃ©mentÃ©
- [ ] **Chiffrement** au repos et en transit activÃ©

### Phase Compliance (Semaine 3-4)  
- [ ] **Analyse RGPD** complÃ©tÃ©e pour tous les cas d'usage IA
- [ ] **Consentement management** system dÃ©ployÃ©
- [ ] **Anonymisation/pseudonymisation** workflows implÃ©mentÃ©s
- [ ] **Droits des personnes** (accÃ¨s, rectification, suppression) automatisÃ©s
- [ ] **Privacy notices** mises Ã  jour avec dÃ©tails IA

### Phase QualitÃ© (Semaine 5-6)
- [ ] **Data quality rules** dÃ©finies avec Great Expectations
- [ ] **Monitoring continu** de la dÃ©rive des donnÃ©es
- [ ] **Alerting automatique** sur les problÃ¨mes qualitÃ©
- [ ] **Lineage tracking** complet des pipelines ML
- [ ] **Validation gates** avant entraÃ®nement modÃ¨les

### Phase Audit (Semaine 7-8)
- [ ] **Model registry** avec mÃ©tadonnÃ©es gouvernance
- [ ] **Processus d'approbation** modÃ¨les pour production
- [ ] **Audit trails** complets des dÃ©cisions IA
- [ ] **Rapports de compliance** automatisÃ©s
- [ ] **Tests de sÃ©curitÃ©** rÃ©guliers (adversarial attacks)

---

**La gouvernance des donnÃ©es n'est pas une contrainte mais un enabler de l'IA de confiance. Sans donnÃ©es de qualitÃ© et processes robustes, mÃªme les meilleurs algorithmes Ã©chouent.**

*Prochaine Ã©tape : [Chapitre 5 - Ã‰quipes & CompÃ©tences](05-equipe-competences.md)*